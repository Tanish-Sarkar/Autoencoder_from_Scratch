{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6cca41b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")  # so we can import from src\n",
    "\n",
    "# from src.model import build_autoencoder\n",
    "from src.train import load_creditcard_data, prepare_datasets, scale_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c090da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple fully-connected autoencoder for tabular data.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim: int, latent_dim: int = 16):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder: input -> latent\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, latent_dim),\n",
    "        )\n",
    "\n",
    "        # Decoder: latent -> input\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        z = self.encoder(x)\n",
    "        recon = self.decoder(z)\n",
    "        return recon\n",
    "\n",
    "def build_autoencoder(input_dim: int, latent_dim: int = 16) -> Autoencoder:\n",
    "    return Autoencoder(input_dim=input_dim, latent_dim=latent_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6c9d36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (284807, 31)\n",
      "Columns: ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
      "Created X shape: (284807, 30), y shape: (284807,)\n",
      "Train normal: (255883, 30)\n",
      "Val normal: (28432, 30)\n",
      "Test: (57355, 30)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Try loading directly without the function first\n",
    "csv_path = Path(\"../data/creditcard.csv\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(str(csv_path))\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Create X, y manually\n",
    "    X = df.drop(columns=['Class']).values.astype(np.float32)\n",
    "    y = df['Class'].values.astype(np.float32)\n",
    "    \n",
    "    print(f\"Created X shape: {X.shape}, y shape: {y.shape}\")\n",
    "    \n",
    "    # Continue with your pipeline\n",
    "    (X_train_norm, _), (X_val_norm, _), (X_test, y_test) = prepare_datasets(X, y)\n",
    "    scaler, X_train_scaled, X_val_scaled, X_test_scaled = scale_data(\n",
    "        X_train_norm, X_val_norm, X_test\n",
    "    )\n",
    "    \n",
    "    print(\"Train normal:\", X_train_scaled.shape)\n",
    "    print(\"Val normal:\", X_val_scaled.shape)\n",
    "    print(\"Test:\", X_test_scaled.shape)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at {csv_path.absolute()}\")\n",
    "    print(\"Current working directory:\", Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47f3ade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloader(x, batch_size=512, shuffle=True):\n",
    "    tensor_x = torch.from_numpy(x)\n",
    "    dataset = TensorDataset(tensor_x)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return loader\n",
    "\n",
    "batch_size = 512\n",
    "train_loader = make_dataloader(X_train_scaled, batch_size=batch_size, shuffle=True)\n",
    "val_loader = make_dataloader(X_val_scaled, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4145e8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cpu\n",
      "Model repr:\n",
      " Autoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=30, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=16, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=30, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Model class: <class '__main__.Autoencoder'>\n",
      "Is nn.Module? True\n",
      "Number of parameter tensors: 12\n",
      "Total number of parameters: 26542\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using Device: {device}\")\n",
    "\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "latent_dim = 16\n",
    "\n",
    "model = build_autoencoder(input_dim=input_dim, latent_dim=latent_dim).to(device)\n",
    "\n",
    "print(\"Model repr:\\n\", model)\n",
    "print(\"\\nModel class:\", model.__class__)\n",
    "print(\"Is nn.Module?\", isinstance(model, nn.Module))\n",
    "\n",
    "params = list(model.parameters())\n",
    "print(\"Number of parameter tensors:\", len(params))\n",
    "print(\"Total number of parameters:\", sum(p.numel() for p in params))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34451690",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss(reduction=\"mean\")\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cc1e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
